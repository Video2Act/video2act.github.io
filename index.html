<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="theme-color" content="#020617" />
    <meta
      name="description"
      content="Video2Act: A Dual-System Video Diffusion Policy with Robotic Spatio-Motional Modeling"
    />
    <title>Video2Act</title>
    <!-- Tailwind CSS -->
    <script src="https://cdn.tailwindcss.com"></script>
    <script>
      tailwind.config = {
        theme: {
          extend: {
            colors: {
              brand: {
                dark: '#020617',
                purple: '#7c3aed',
                cyan: '#06b6d4',
              }
            },
            fontFamily: {
              sans: ['"Google Sans"', '"Noto Sans"', 'system-ui', 'sans-serif'],
            },
            animation: {
              'blob': 'blob 7s infinite',
            },
            keyframes: {
              blob: {
                '0%': { transform: 'translate(0px, 0px) scale(1)' },
                '33%': { transform: 'translate(30px, -50px) scale(1.1)' },
                '66%': { transform: 'translate(-20px, 20px) scale(0.9)' },
                '100%': { transform: 'translate(0px, 0px) scale(1)' },
              }
            }
          },
        },
      }
    </script>
    <!-- Fonts -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Google+Sans:wght@400;500;700;800&family=Noto+Sans:wght@400;500;700&display=swap" rel="stylesheet">
    <!-- Icons -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <script type="importmap">
{
  "imports": {
    "react/": "https://aistudiocdn.com/react@^19.2.0/",
    "react": "https://aistudiocdn.com/react@^19.2.0",
    "react-dom/": "https://aistudiocdn.com/react-dom@^19.2.0/"
  }
}
</script>
</head>
<body>

  <!-- Skip to content -->
  <a class="skip-link" href="#abstract">Skip to content</a>

  <!-- ===== 透明导航栏（含下拉全透明、白字） ===== -->
  <nav class="navbar is-transparent" role="navigation" aria-label="main navigation">
    <div class="navbar-brand">
      <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
        <span aria-hidden="true"></span><span aria-hidden="true"></span><span aria-hidden="true"></span>
      </a>
    </div>
    <div class="navbar-menu">
      <div class="navbar-start" style="flex-grow:1; justify-content:center;">
        <a class="navbar-item" href="#top" aria-label="Home"><span class="icon"><i class="fas fa-home"></i></span></a>
        <div class="navbar-item has-dropdown is-hoverable">
          <a class="navbar-link">Our Related Research</a>
          <div class="navbar-dropdown">
            <a class="navbar-item" href="https://general-flow.github.io/" target="_blank" rel="noopener">General Flow</a>
          </div>
        </div>
      </div>
    </div>
  </nav>

  <!-- ================== Hero Cover ================== -->
  <header id="top" class="cover" aria-label="Hero cover">
    <div class="cover__media" aria-hidden="true">
      <img class="cover__poster" src="resources/cover_poster.jpg" alt="">
      <video id="bg-video"
             autoplay
             loop
             muted
             playsinline
             preload="none"
             poster="resources/cover_poster.jpg">
        <source data-src="resources/cover.mp4"  type="video/mp4">
      </video>
    </div>

    <div class="cover__overlay">
      <div class="cover__content">
        <h1 class="cover__title" aria-label="MotionTrans: Human VR Data Enable Motion-Level Learning for Robotic Manipulation Policies">
          <span class="brand" aria-label="MotionTrans">
            <span class="brand__fill">Video2Act</span>
            <span class="brand__stroke" aria-hidden="true">Video2Act</span>
          </span>

          <span class="rest">
            <span class="line">A Dual-System Video Diffusion Policy with Robotic Spatio-Motional Modeling</span>
            <span class="line">for Robotic Manipulation Policies</span>
          </span>
        </h1>

        <!-- ===== Authors ===== -->
        <div class="cover__subtitle" id="authors-line">
          <a href="https://jiayueru.github.io/">Yueru Jia</a><sup>1,2*</sup>&nbsp;&nbsp;&nbsp;
          <a href="https://liujiaming1996.github.io/">Jiaming Liu</a><sup>1,2*</sup>&nbsp;&nbsp;&nbsp;
          <a href="">Shengbang Liu</a><sup>3*</sup>&nbsp;&nbsp;&nbsp;
          <a href="https://zhourui9813.github.io/">Rui Zhou</a><sup>4</sup>&nbsp;&nbsp;&nbsp;
          <a href="">Wanhe Yu</a><sup>1</sup>&nbsp;&nbsp;&nbsp;
          <a href="">Yuyang Yan</a><sup>1</sup>&nbsp;&nbsp;&nbsp;
          <a href="">Xiaowei Chi</a><sup>5</sup>&nbsp;&nbsp;&nbsp;
          <a href="">Yandong Guo</a><sup>2</sup>&nbsp;&nbsp;&nbsp;
          <a href="https://camera.pku.edu.cn/">Boxin Shi</a><sup>1</sup>&nbsp;&nbsp;&nbsp;
          <a href="https://www.shanghangzhang.com/">Shanghang Zhang</a><sup>1</sup>&nbsp;&nbsp;&nbsp;
        </div>

        <div class="cover__meta">
          <sup>1</sup> State Key Laboratory of Multimedia Information Processing, School of Computer Science&nbsp;&nbsp;
          <sup>2</sup> AI2 Robotics<br>
          <sup>3</sup> Sun Yat-sen University<br>
          <sup>4</sup> Wuhan University&nbsp;&nbsp;
          <sup>5</sup> Hong Kong University of Science and Technology<br>
          <span class="has-text-grey" style="font-size:.9em;">* Equal contribution <span style="font-family:serif;">†</span> Corresponding author</span>
        </div>

        <div class="cover__actions">
          <a class="cover__btn" href="./resources/" target="_blank" rel="noopener"><i class="fas fa-file-pdf"></i><span>Paper (PDF)</span></a>
          <a class="cover__btn" href="https://arxiv.org/" target="_blank" rel="noopener"><i class="ai ai-arxiv"></i><span>arXiv</span></a>
          <a class="cover__btn" href="https://github.com/" target="_blank" rel="noopener"><i class="fab fa-github"></i><span>Code</span></a>
          <a class="cover__btn" href="https://github.com/" target="_blank" rel="noopener"><i class="fas fa-code"></i><span>VLA Code</span></a>
          <a class="cover__btn" href="https://huggingface.co/" target="_blank" rel="noopener"><img src="resources/hf-logo.png" alt="" style="width:1em;height:1em;"><span>Datasets</span></a>
        </div>
      </div>
    </div>
  </header>

  <!-- ================== Project Video (YouTube) ================== -->
<section class="section mt-section section--after-cover" id="teaser">
  <div class="container">
    <h2 class="title is-2 mt-title">Project Video</h2>
    <div class="mt-card w-70">
      <div class="mt-video-wrap">
        <video
          class="mt-video"
          controls
          preload="metadata"
          style="width:100%; border-radius:10px;"
        >
          <source src="./resources/video2act_demo.mp4" type="video/mp4">
          Your browser does not support the video tag.
        </video>
      </div>
      <p style="text-align:center; margin-top:10px; font-weight:800; color:#111827;">
        Teaser / Project video
      </p>
    </div>
  </div>
</section>



  <!-- ================== Abstract ================== -->
  <section class="section mt-section" id="abstract">
    <div class="container">
      <h2 class="title is-2 mt-title">Abstract</h2>
      <div class="columns is-centered">
        <div class="column is-two-thirds">
          <div class="mt-card" style="backdrop-filter: blur(4px); background: linear-gradient(180deg, rgba(255,255,255,.95), rgba(255,255,255,.9)); border-left:4px solid #7c3aed;">
            <div class="content has-text-justified" style="margin:0;">
              <p>
                Robust perception and dynamics modeling are fundamental to real-world robotic policy learning. 
                Recent methods employ video diffusion models (VDMs) to enhance robotic policies, improving their understanding and modeling of the physical world.
                However, existing approaches overlook the coherent and physically consistent motion representations inherently encoded across frames in VDMs.
                To this end, we propose Video2Act, a framework that efficiently guides robotic action learning by explicitly integrating spatial and motion-aware representations.
                Building on the inherent representations of VDMs, we extract foreground boundaries and inter-frame motion variations while filtering out background noise and task-irrelevant biases.
                These refined representations are then used as additional conditioning inputs to a diffusion transformer (DiT) action head, enabling it to reason about what to manipulate and how to move.
                To mitigate inference inefficiency, we propose an asynchronous dual-system design, where the VDM functions as the slow System 2 and the DiT head as the fast System 1, working collaboratively to generate adaptive actions.
                By providing motion-aware conditions to System 1, Video2Act maintains stable manipulation even with low-frequency updates from the VDM.
                For evaluation, Video2Act surpasses previous state-of-the-art VLA methods by 7.7% in simulation and 21.7% in real-world tasks in terms of average success rate, further exhibiting strong generalization capabilities.
              </p>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- ================== Video2Act Overview ================== -->
  <section class="section mt-section" id="unified-human-centric">
    <div class="container">
      <h2 class="title is-2 mt-title">Video2Act Overview</h2>
    <div class="mt-card w-70">
        <div class="mt-img-wrap">
          <img src="./resources/pipline.png" alt="MotionTrans pipeline from VR human data to deployable robot policies">
        </div>
        <p style="text-align:center; margin-top:10px; font-weight:800; color:#111827;">
          We visualize Grad-CAM activations for DINOv2, SigLIP and the Video Diffusion Model (VDM) during the block handover task, observed from two common robotic settings: a static third-person (Head Camera View) and a dynamic ego-centric (Wrist Camera View). The heatmaps for standard image encoders (DINOv2, SigLIP) are diffuse, unstable, and shift focus irregularly. In contrast, the VDM features consistently attend to the foreground objects being manipulated, demonstrating strong spatial structure awareness even under severe ego-motion.
        </p>
      </div>
    </div>
  </section>

  <!-- ================== Feature ================== -->
  <section class="section mt-section" id="unified-human-centric">
    <div class="container">
      <h2 class="title is-2 mt-title">Qualitative analysis of latent representations</h2>
    <div class="mt-card w-70">
        <div class="mt-img-wrap">
          <img src="./resources/feature.png" alt="MotionTrans pipeline from VR human data to deployable robot policies">
        </div>
        <p style="text-align:center; margin-top:10px; font-weight:800; color:#111827;">
          Video2Act employs an asynchronous dual-system framework consisting of a slow perceptual VDM (System 2) and a fast action head (System 1). System 2 extracts refined spatial and motion representations from two image inputs: high-resolution images for spatial filtering via Sobel operators and long-horizon sequences for motion extraction via FFT. These low-frequency spatio-motional features serve as conditioning inputs to System 1, which simultaneously receives high-frequency image tokens. Through cross-attention conditioning, these asynchronously updated signals are effectively fused, enabling robust and real-time action generation.
        </p>
      </div>
    </div>
  </section>

  <!-- ================== RoboTwin Simulation ================== -->
<section class="section mt-section" id="zero-shot">
  <div class="container">
    <h2 class="title is-2 mt-title">RoboTwin Simulation</h2>
    <p class="has-text-grey" style="text-align:center; margin-bottom:12px;">
      RoboTwin Simulation
    </p>

    <div class="mt-card" id="zeroShotBlock">
      <style>
        /* 区块标题 */
        #zero-shot .mt-seg-header{
          display:flex;
          flex-direction:column;
          align-items:center;
          gap:4px;
          margin-bottom:20px;
          text-align:center;
        }
        #zero-shot .mt-seg-title{
          display:inline-flex;
          align-items:center;
          gap:10px;
          font-weight:800;
          color:#111827;
          letter-spacing:.3px;
          font-size:1.15rem;
        }
        #zero-shot .mt-seg-title::before{
          content:"";
          width:12px;
          height:12px;
          border-radius:50%;
          background:linear-gradient(90deg,#7c3aed,#06b6d4);
          box-shadow:0 0 0 6px rgba(124,58,237,.16);
        }
        #zero-shot .mt-seg-subtitle{
          font-size:.9rem;
          color:#6b7280;
        }

        /* 视频网格整体 */
        #resultVideoPager{
          --gap: 24px;
          --badge-bg: rgba(0,0,0,.60);
          --badge-shadow: 0 4px 14px rgba(0,0,0,.35);
          margin-top: 8px;
        }
        #resultVideoPager .rvp-grid{
          display:grid;
          grid-template-columns: repeat(3, 1fr);
          gap: var(--gap);
          max-width: 1200px;
          margin: 0 auto;
        }
        @media (max-width: 992px){
          #resultVideoPager .rvp-grid{
            grid-template-columns: repeat(2, 1fr);
          }
        }
        @media (max-width: 576px){
          #resultVideoPager .rvp-grid{
            grid-template-columns: 1fr;
          }
        }

        /* 单个视频卡片 */
        #resultVideoPager .rvp-item{
          display:flex;
          flex-direction:column;
          background:#ffffff;
          border-radius:16px;
          padding:12px 12px 14px;
          box-shadow:0 12px 30px rgba(15,23,42,.12);
          transition:transform .18s ease-out, box-shadow .18s ease-out;
        }
        #resultVideoPager .rvp-item:hover{
          transform:translateY(-4px);
          box-shadow:0 18px 40px rgba(15,23,42,.16);
        }

        /* 视频容器 */
        #resultVideoPager .rvp-video{
          position:relative;
          width:100%;
          aspect-ratio:16/9;
          border-radius:12px;
          overflow:hidden;
          background:#000;
        }
        #resultVideoPager .rvp-video::after{
          content:"";
          position:absolute;
          inset:0;
          background:linear-gradient(to top, rgba(0,0,0,.45), transparent 40%);
          pointer-events:none;
        }

        /* 视频标签本身 */
        #resultVideoPager .rvp-video video{
          width:100%;
          height:100%;
          object-fit:cover;
          display:block;
          opacity:0;
          transition:opacity .25s ease-out;
        }
        #resultVideoPager .rvp-video video.is-ready{
          opacity:1;
        }

        /* 左上角徽标 */
        #resultVideoPager .rvp-badge{
          position:absolute;
          top:10px;
          left:10px;
          padding:6px 11px;
          border-radius:999px;
          background: var(--badge-bg);
          color:#f9fafb;
          font-size:11px;
          letter-spacing:.12em;
          text-transform:uppercase;
          box-shadow: var(--badge-shadow);
          user-select:none;
          z-index:2;
        }

        /* 右下角小播放图标 */
        #resultVideoPager .rvp-play-icon{
          position:absolute;
          right:10px;
          bottom:10px;
          width:26px;
          height:26px;
          border-radius:999px;
          border:1px solid rgba(249,250,251,.4);
          display:flex;
          align-items:center;
          justify-content:center;
          background:rgba(249,250,251,.12);
          backdrop-filter:blur(4px);
          z-index:2;
        }
        #resultVideoPager .rvp-play-icon::before{
          content:"";
          border-style:solid;
          border-width:5px 0 5px 9px;
          border-color:transparent transparent transparent #f9fafb;
          margin-left:2px;
        }

        /* 标题/说明 */
        #resultVideoPager .rvp-caption{
          text-align:center;
          margin-top:10px;
          font-size:.95rem;
          color:#374151;
          font-weight:600;
        }

        /* 仿真定量结果在同一卡片内的样式 */
        #zero-shot .mt-quant-fig{
          margin:22px 0 0;
          padding:16px;
          background:#ffffff;
          border-radius:16px;
          box-shadow:0 10px 28px rgba(15,23,42,.12);
        }
        #zero-shot .mt-quant-fig img{
          display:block;
          width:100%;
          height:auto;
          border-radius:10px;
        }
        #zero-shot .mt-quant-fig figcaption{
          margin-top:8px;
          text-align:center;
          font-size:.9rem;
          color:#6b7280;
        }
      </style>

      <!-- 标题区 -->
      <div class="mt-seg-header">
        <div class="mt-seg-title">Simulation Gallery</div>
        <p class="mt-seg-subtitle">
          A collection of RoboTwin simulation rollouts under different tasks.
        </p>
      </div>

      <!-- 视频网格 -->
      <div id="resultVideoPager" class="video-pager" aria-label="RoboTwin Simulation"></div>

      <script>
        (function () {
          const pager = document.getElementById('resultVideoPager');
          if (!pager) return;

          const simVideos = [
            { title: "Block Handover", src: "resources/robotwin_rollout/block_handover_D435/episode0/video.mp4" },
            { title: "Container Place", src: "resources/robotwin_rollout/container_place_D435/episode0/video.mp4" },
            { title: "Dual Bottles Pick (Easy)", src: "resources/robotwin_rollout/dual_bottles_pick_easy_D435/episode0/video.mp4" },
            { title: "Dual Bottles Pick (Hard)", src: "resources/robotwin_rollout/dual_bottles_pick_hard_D435/episode0/video.mp4" },
            { title: "Empty Cup Place", src: "resources/robotwin_rollout/empty_cup_place_D435/episode0/video.mp4" },
            { title: "Pick Apple Messy", src: "resources/robotwin_rollout/pick_apple_messy_D435/episode0/video.mp4" }
          ];

          const grid = document.createElement('div');
          grid.className = 'rvp-grid';

          simVideos.forEach(video => {
            const item = document.createElement('div');
            item.className = 'rvp-item';
            item.innerHTML = `
              <div class="rvp-video">
                <span class="rvp-badge">Robotwin</span>
                <div class="rvp-play-icon"></div>
                <video muted loop playsinline controls preload="metadata" src="${video.src}">
                  Your browser does not support the video tag.
                </video>
              </div>
              <div class="rvp-caption">${video.title}</div>
            `;
            grid.appendChild(item);
          });

          pager.appendChild(grid);

          grid.querySelectorAll('video').forEach(video => {
            const markReady = () => video.classList.add('is-ready');
            if (video.readyState >= 2) {
              markReady();
            } else {
              video.addEventListener('loadeddata', markReady, { once: true });
            }
          });
        })();
      </script>

      <!-- 仿真定量结果图（与视频同一卡片） -->
      <figure class="mt-quant-fig">
        <img src="resources/RoboTwinSR.png" alt="RoboTwin simulation quantitative results">
        <figcaption>RoboTwin simulation: quantitative success rates across tasks.</figcaption>
      </figure>
    </div>
  </div>
</section>


<!-- ================== Real Robot Experiments ================== -->
<section class="section mt-section" id="real-robot">
  <div class="container">
    <h2 class="title is-2 mt-title">Real Robot Experiments</h2>
    <p class="has-text-grey" style="text-align:center; margin-bottom:12px;">
      Real robot execution of the RoboTwin tasks
    </p>

    <div class="mt-card" id="realRobotBlock">
      <style>
        /* 区块标题 */
        #real-robot .mt-seg-header{
          display:flex;
          flex-direction:column;
          align-items:center;
          gap:4px;
          margin-bottom:20px;
          text-align:center;
        }
        #real-robot .mt-seg-title{
          display:inline-flex;
          align-items:center;
          gap:10px;
          font-weight:800;
          color:#111827;
          letter-spacing:.3px;
          font-size:1.15rem;
        }
        #real-robot .mt-seg-title::before{
          content:"";
          width:12px;
          height:12px;
          border-radius:50%;
          background:linear-gradient(90deg,#7c3aed,#06b6d4);
          box-shadow:0 0 0 6px rgba(124,58,237,.16);
        }
        #real-robot .mt-seg-subtitle{
          font-size:.9rem;
          color:#6b7280;
        }

        /* 视频网格整体 */
        #realRobotPager{
          --gap: 24px;
          --badge-bg: rgba(0,0,0,.60);
          --badge-shadow: 0 4px 14px rgba(0,0,0,.35);
          margin-top: 8px;
        }
        #realRobotPager .rvp-grid{
          display:grid;
          grid-template-columns: repeat(3, 1fr);
          gap: var(--gap);
          max-width: 1200px;
          margin: 0 auto;
        }
        @media (max-width: 992px){
          #realRobotPager .rvp-grid{
            grid-template-columns: repeat(2, 1fr);
          }
        }
        @media (max-width: 576px){
          #realRobotPager .rvp-grid{
            grid-template-columns: 1fr;
          }
        }

        /* 单个视频卡片 */
        #realRobotPager .rvp-item{
          display:flex;
          flex-direction:column;
          background:#ffffff;
          border-radius:16px;
          padding:12px 12px 14px;
          box-shadow:0 12px 30px rgba(15,23,42,.12);
          transition:transform .18s ease-out, box-shadow .18s ease-out;
        }
        #realRobotPager .rvp-item:hover{
          transform:translateY(-4px);
          box-shadow:0 18px 40px rgba(15,23,42,.16);
        }

        /* 视频容器 */
        #realRobotPager .rvp-video{
          position:relative;
          width:100%;
          aspect-ratio:16/9;
          border-radius:12px;
          overflow:hidden;
          background:#000;
        }
        #realRobotPager .rvp-video::after{
          content:"";
          position:absolute;
          inset:0;
          background:linear-gradient(to top, rgba(0,0,0,.45), transparent 40%);
          pointer-events:none;
        }

        /* 视频标签本身 */
        #realRobotPager .rvp-video video{
          width:100%;
          height:100%;
          object-fit:cover;
          display:block;
          opacity:0;
          transition:opacity .25s ease-out;
        }
        #realRobotPager .rvp-video video.is-ready{
          opacity:1;
        }

        /* 左上角徽标 */
        #realRobotPager .rvp-badge{
          position:absolute;
          top:10px;
          left:10px;
          padding:6px 11px;
          border-radius:999px;
          background: var(--badge-bg);
          color:#f9fafb;
          font-size:11px;
          letter-spacing:.12em;
          text-transform:uppercase;
          box-shadow: var(--badge-shadow);
          user-select:none;
          z-index:2;
        }

        /* 右下角小播放图标 */
        #realRobotPager .rvp-play-icon{
          position:absolute;
          right:10px;
          bottom:10px;
          width:26px;
          height:26px;
          border-radius:999px;
          border:1px solid rgba(249,250,251,.4);
          display:flex;
          align-items:center;
          justify-content:center;
          background:rgba(249,250,251,.12);
          backdrop-filter:blur(4px);
          z-index:2;
        }
        #realRobotPager .rvp-play-icon::before{
          content:"";
          border-style:solid;
          border-width:5px 0 5px 9px;
          border-color:transparent transparent transparent #f9fafb;
          margin-left:2px;
        }

        /* 标题/说明 */
        #realRobotPager .rvp-caption{
          text-align:center;
          margin-top:10px;
          font-size:.95rem;
          color:#374151;
          font-weight:600;
        }

        /* 真机定量结果在同一卡片内的样式 */
        #real-robot .mt-quant-fig{
          margin:22px 0 0;
          padding:16px;
          background:#ffffff;
          border-radius:16px;
          box-shadow:0 10px 28px rgba(15,23,42,.12);
        }
        #real-robot .mt-quant-fig img{
          display:block;
          width:100%;
          height:auto;
          border-radius:10px;
        }
        #real-robot .mt-quant-fig figcaption{
          margin-top:8px;
          text-align:center;
          font-size:.9rem;
          color:#6b7280;
        }
      </style>

      <!-- 标题区 -->
      <div class="mt-seg-header">
        <div class="mt-seg-title">Real Robot Gallery</div>
        <p class="mt-seg-subtitle">
          Real-world executions corresponding to the six RoboTwin tasks.
        </p>
      </div>

      <!-- 视频网格 -->
      <div id="realRobotPager" class="video-pager" aria-label="Real Robot Experiments"></div>

      <script>
        (function () {
          const pager = document.getElementById('realRobotPager');
          if (!pager) return;

          const realVideos = [
            { title: "block handover", src: "resources/success_demo/close_laptop.mp4" },
            { title: "container place", src: "resources/success_demo/handover_cucumber.mp4" },
            { title: "dual bottles pick easy", src: "resources/success_demo/pick_carrot.mp4" },
            { title: "dual bottles pick hard", src: "resources/success_demo/pick_dual_carrot.mp4" },
            { title: "empty cup place", src: "resources/success_demo/pick_flowers.mp4" },
            { title: "pick apple messy", src: "resources/success_demo/push_triangle.mp4" }
          ];

          const grid = document.createElement('div');
          grid.className = 'rvp-grid';

          realVideos.forEach(video => {
            const item = document.createElement('div');
            item.className = 'rvp-item';
            item.innerHTML = `
              <div class="rvp-video">
                <span class="rvp-badge">Real robot</span>
                <div class="rvp-play-icon"></div>
                <video muted loop playsinline controls preload="metadata" src="${video.src}">
                  Your browser does not support the video tag.
                </video>
              </div>
              <div class="rvp-caption">${video.title}</div>
            `;
            grid.appendChild(item);
          });

          pager.appendChild(grid);

          grid.querySelectorAll('video').forEach(video => {
            const markReady = () => video.classList.add('is-ready');
            if (video.readyState >= 2) {
              markReady();
            } else {
              video.addEventListener('loadeddata', markReady, { once: true });
            }
          });
        })();
      </script>

      <!-- 真机定量结果图（与视频同一卡片） -->
      <figure class="mt-quant-fig">
        <img src="resources/RealSuccessRate.png" alt="Real robot quantitative results">
        <figcaption>Real robot experiments: success rates over different tasks.</figcaption>
      </figure>
    </div>
  </div>
</section>



<!-- ================== Generalization Experiments ================== -->
<section class="section mt-section" id="generalization">
  <div class="container">
    <h2 class="title is-2 mt-title">Generalization Experiments</h2>
    <p class="has-text-grey" style="text-align:center; margin-bottom:12px;">
      Visual and quantitative results of our generalization experiments.
    </p>

    <div class="mt-card" id="generalizationBlock">
      <style>
        /* 标题区 */
        #generalization .mt-seg-header{
          display:flex;
          flex-direction:column;
          align-items:center;
          gap:4px;
          margin-bottom:20px;
          text-align:center;
        }
        #generalization .mt-seg-title{
          display:inline-flex;
          align-items:center;
          gap:10px;
          font-weight:800;
          color:#111827;
          letter-spacing:.3px;
          font-size:1.15rem;
        }
        #generalization .mt-seg-title::before{
          content:"";
          width:12px;
          height:12px;
          border-radius:50%;
          background:linear-gradient(90deg,#7c3aed,#06b6d4);
          box-shadow:0 0 0 6px rgba(124,58,237,.16);
        }
        #generalization .mt-seg-subtitle{
          font-size:.9rem;
          color:#6b7280;
        }

        /* 整体容器 */
        #generalizationGrid{
          display:flex;
          flex-direction:column;
          gap:24px;
          margin-top:8px;
        }

        /* 每一行（carrot / cucumber） */
        .gen-row{
          display:flex;
          flex-direction:column;
          gap:12px;
          padding:14px 16px;
          border-radius:16px;
          background:#ffffff;
          box-shadow:0 10px 26px rgba(15,23,42,.10);
        }

        /* 行标题：放在视频上方 */
        .gen-row-header{
          font-weight:700;
          font-size:1rem;
          color:#111827;
        }

        .gen-row-videos{
          flex:1;
          display:grid;
          grid-template-columns:repeat(3, minmax(0, 1fr));
          gap:16px;
        }
        @media (max-width: 576px){
          .gen-row-videos{
            grid-template-columns:1fr;
          }
        }

        /* 单个视频卡片 */
        .gen-item{
          display:flex;
          flex-direction:column;
        }
        .gen-video-wrap{
          position:relative;
          width:100%;
          aspect-ratio:16/9;
          border-radius:12px;
          overflow:hidden;
          background:#000;
          box-shadow:0 8px 22px rgba(15,23,42,.16);
        }
        .gen-video-wrap::after{
          content:"";
          position:absolute;
          inset:0;
          background:linear-gradient(to top, rgba(0,0,0,.4), transparent 40%);
          pointer-events:none;
        }
        .gen-video-wrap video{
          width:100%;
          height:100%;
          object-fit:cover;
          display:block;
        }

        .gen-badge{
          position:absolute;
          top:8px;
          left:8px;
          padding:5px 10px;
          border-radius:999px;
          background:rgba(0,0,0,.6);
          color:#f9fafb;
          font-size:11px;
          letter-spacing:.08em;
          text-transform:uppercase;
          z-index:2;
        }

        .gen-caption{
          margin-top:6px;
          text-align:center;
          font-size:.9rem;
          color:#4b5563;
          font-weight:500;
        }

        /* 柱状图定量结果在同一卡片内样式 */
        #generalization .mt-quant-fig{
          margin:22px 0 0;
          padding:16px;
          background:#ffffff;
          border-radius:16px;
          box-shadow:0 10px 28px rgba(15,23,42,.12);
        }
        #generalization .mt-quant-fig img{
          display:block;
          width:100%;
          height:auto;
          border-radius:10px;
        }
        #generalization .mt-quant-fig figcaption{
          margin-top:8px;
          text-align:center;
          font-size:.9rem;
          color:#6b7280;
        }
      </style>

      <!-- 标题区 -->
      <div class="mt-seg-header">
        <div class="mt-seg-title">Generalization Visualizations</div>
        <p class="mt-seg-subtitle">
          Each row shows how the policy generalizes to changes in background, lighting and objects.
        </p>
      </div>

      <!-- 两行：carrot & cucumber -->
      <div id="generalizationGrid">

        <!-- Carrot row -->
        <div class="gen-row">
          <div class="gen-row-header">Carrot Generalization</div>
          <div class="gen-row-videos">
            <div class="gen-item">
              <div class="gen-video-wrap">
                <span class="gen-badge">Background</span>
                <video muted loop playsinline controls preload="metadata"
                       src="resources/generalization_carrot/background.mp4">
                  Your browser does not support the video tag.
                </video>
              </div>
              <div class="gen-caption">Background change</div>
            </div>

            <div class="gen-item">
              <div class="gen-video-wrap">
                <span class="gen-badge">Light</span>
                <video muted loop playsinline controls preload="metadata"
                       src="resources/generalization_carrot/light.mp4">
                  Your browser does not support the video tag.
                </video>
              </div>
              <div class="gen-caption">Lighting change</div>
            </div>

            <div class="gen-item">
              <div class="gen-video-wrap">
                <span class="gen-badge">Object</span>
                <video muted loop playsinline controls preload="metadata"
                       src="resources/generalization_carrot/object.mp4">
                  Your browser does not support the video tag.
                </video>
              </div>
              <div class="gen-caption">Object change</div>
            </div>
          </div>
        </div>

        <!-- Cucumber row -->
        <div class="gen-row">
          <div class="gen-row-header">Cucumber Generalization</div>
          <div class="gen-row-videos">
            <div class="gen-item">
              <div class="gen-video-wrap">
                <span class="gen-badge">Background</span>
                <video muted loop playsinline controls preload="metadata"
                       src="resources/generalization_cucumber/background.mp4">
                  Your browser does not support the video tag.
                </video>
              </div>
              <div class="gen-caption">Background change</div>
            </div>

            <div class="gen-item">
              <div class="gen-video-wrap">
                <span class="gen-badge">Light</span>
                <video muted loop playsinline controls preload="metadata"
                       src="resources/generalization_cucumber/light.mp4">
                  Your browser does not support the video tag.
                </video>
              </div>
              <div class="gen-caption">Lighting change</div>
            </div>

            <div class="gen-item">
              <div class="gen-video-wrap">
                <span class="gen-badge">Object</span>
                <video muted loop playsinline controls preload="metadata"
                       src="resources/generalization_cucumber/object.mp4">
                  Your browser does not support the video tag.
                </video>
              </div>
              <div class="gen-caption">Object change</div>
            </div>
          </div>
        </div>

      </div> <!-- /generalizationGrid -->

      <!-- Generalization quantitative results (bar chart, 与视频同一卡片) -->
      <figure class="mt-quant-fig">
        <img src="resources/Generalization.png"
             alt="Generalization quantitative results">
        <figcaption>Quantitative evaluation of generalization over background, lighting and object changes.</figcaption>
      </figure>
    </div>
  </div>
</section>


  <!-- ================== Acknowledgments ================== -->
  <section class="section mt-section" id="acknowledgments">
    <div class="container">
      <h2 class="title is-2 mt-title">Acknowledgments</h2>
      <div class="mt-card">
        <div class="content has-text-justified" style="margin:0;">
          <p>
            We would like to express our sincere gratitude to
            <strong>Shuo Wang</strong>, <strong>Gu Zhang</strong>, <strong>Enshen Zhou</strong>, <strong>Haoxu Huang</strong>,
            <strong>Jialei Huang</strong>, <strong>Ruiqian Nai</strong>, <strong>Zhengrong Xue</strong>, <strong>Junmin Zhao</strong>,
            and <strong>Weirui Ye</strong> for their valuable discussions. We are especially grateful to
            <strong>Ruiqian Nai</strong> and <strong>Fanqi Lin</strong> for their assistance with the implementation of Pi0-VLA,
            and to <strong>Yankai Fu</strong> for his support with the hardware implementation.
            Our thanks also extend to the SpiritAI and InspireRobot team for their assistance.
          </p>
        </div>
      </div>
    </div>
  </section>

  <!-- ================== BibTeX ================== -->
  <section class="section mt-section" id="BibTeX">
    <div class="container">
      <h2 class="title is-2 mt-title">BibTeX</h2>
      <div class="mt-card">
<pre><code>
@article{yuan2025motiontrans,
  title={MotionTrans: Human VR Data Enable Motion-Level Learning for Robotic Manipulation Policies},
  author={Yuan, Chengbo and Zhou, Rui and Liu, Mengzhen and Hu, Yingdong and Wang, Shengjie and Yi, Li and Wen, Chuan and Zhang, Shanghang and Gao, Yang},
  journal={arXiv preprint arXiv:2509.17759},
  year={2025}
}
</code></pre>
      </div>
    </div>
  </section>

  <!-- ===== JS：汉堡菜单、媒体淡入 + 封面视频懒加载 ===== -->
  <script>
    (function(){
      const burger = document.querySelector('.navbar-burger');
      const menu   = document.querySelector('.navbar-menu');
      if(burger && menu){
        burger.addEventListener('click', ()=>{ burger.classList.toggle('is-active'); menu.classList.toggle('is-active'); });
      }

      const bg = document.getElementById('bg-video');
      if (bg) {
        bg.querySelectorAll('source').forEach(s => {
          if (s.dataset.src) s.src = s.dataset.src;
        });
        requestAnimationFrame(() => bg.load());
        const markReady = () => bg.classList.add('is-ready');
        bg.addEventListener('canplay', markReady, { once:true });
        bg.addEventListener('loadeddata', markReady, { once:true });
      }

      document.querySelectorAll('img').forEach(img=>{
        const mark=()=>img.classList.add('is-ready');
        if(img.complete) mark(); else img.addEventListener('load', mark, {once:true});
      });
      document.querySelectorAll('video').forEach(v=>{
        const mark=()=>v.classList.add('is-ready');
        if(v.readyState >= 2) mark(); else v.addEventListener('loadeddata', mark, {once:true});
      });

      // 让 YouTube iframe 也做淡入
      document.querySelectorAll('iframe[data-yt]').forEach(f=>{
        const mark = () => f.classList.add('is-ready');
        f.addEventListener('load', mark, { once: true });
      });
    })();
  </script>

</body>
</html>
